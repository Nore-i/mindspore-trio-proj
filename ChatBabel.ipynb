{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c04d64",
   "metadata": {},
   "source": [
    "### current directory: /home/lzc/mindspore/ChatBabel.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34820db-8267-4795-9037-c6a9d8273fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/data1/model/bge1_5-large-zh'\n",
    "llm_path = '/data1/model/qwen1_5-7b-chat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c794505",
   "metadata": {},
   "source": [
    "## Preparing papers\n",
    "1. Locate the zip file that contains the papers and unzip them into the `./data` repository.\n",
    "2. Manually create a .bib file that contains all the metadata for the papers and store them in `./bib_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9915ec49-c7d2-419b-b5d4-8b3613c02f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture captured_output\n",
    "# !unzip papers_condensed.zip -d ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a750c9-94b8-48e2-ac0f-4181bbc1b9ac",
   "metadata": {},
   "source": [
    "# 1. Preparation for PDF loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ad1b1d-bbd1-4410-a7d6-92c6541419de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A Survey on Evolutionary Computation for Computer Vision and Image Analysis: Past, Present, and Future Trends', 'Bi, Ying')\n",
      "('Modified Distance Calculation in Generational Distance and Inverted Generational Distance', 'Ishibuchi, Hisao')\n",
      "('Unknown title', 'Unknown author')\n",
      "('The Pareto archived evolution strategy: a new baseline algorithm for Pareto multiobjective optimisation', 'Knowles, J.')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Unknown title', 'Unknown author')\n",
      "('A Scalable Multi-objective Test Problem Toolkit', 'Huband, Simon')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Performance of Decomposition-Based Many-Objective Algorithms Strongly Depends on Pareto Front Shapes', 'Ishibuchi, Hisao')\n",
      "('The CMA Evolution Strategy: A Tutorial', 'Hansen, Nikolaus')\n",
      "('MOEA/D: A Multiobjective Evolutionary Algorithm Based on Decomposition', '{Qingfu Zhang}')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Comparison of Multiobjective Evolutionary Algorithms: Empirical Results', 'Zitzler, Eckart')\n",
      "('A parallel global multiobjective framework for optimization: pagmo', 'Biscani, Francesco')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Unknown title', 'Unknown author')\n",
      "('A Niched-Penalty Approach for Constraint Handling in Genetic Algorithms', 'Deb, Kalyanmoy')\n",
      "('SMS-EMOA: Multiobjective selection based on dominated hypervolume', 'Beume, Nicola')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Theory of the hypervolume indicator: optimal Î¼-distributions and the choice of the reference point', 'Auger, Anne')\n",
      "('HypE: An Algorithm for Fast Hypervolume-Based Many-Objective Optimization', 'Bader, Johannes')\n",
      "('Unknown title', 'Unknown author')\n",
      "('Multiobjective evolutionary algorithms: a comparative case study and the strength Pareto approach', 'Zitzler, E.')\n",
      "('Simulated Binary Crossover for Continuous Search Space', 'Deb, Kalyanmoy')\n",
      "('A unified model for multi-objective evolutionary algorithms with elitism', 'Laumanns, M.')\n",
      "('Unknown title', 'Unknown author')\n",
      "('A multi-objective genetic local search algorithm and its application to flowshop scheduling', 'Ishibuchi, H.')\n",
      "('Scalable multi-objective optimization test problems', 'Deb, K.')\n",
      "('Unknown title', 'Unknown author')\n",
      "{'title': 'Unknown title', 'author': 'Unknown author'}\n"
     ]
    }
   ],
   "source": [
    "### Preprocess pdf documents\n",
    "import pdfplumber\n",
    "import pdftotext\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# modified from https://stackoverflow.com/questions/77045559/langchain-load-with-string\n",
    "def get_text_chunks_langchain(text, title, author):\n",
    "    \"\"\" Turns raw string into docs that conform with docs = loader.load()\"\"\"\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len\n",
    "    )\n",
    "    docs = [Document(page_content=x, metadata={\"title\":title, \"author\":author}) for x in text_splitter.split_text(text)]\n",
    "    return docs\n",
    "\n",
    "def load_pdf(filepath, bib_file):\n",
    "    \"\"\" From a pdf, return a docs\"\"\"\n",
    "    text = \"\"\n",
    "    match = get_title_author_from_pdf(filepath, bib_file)[0]\n",
    "    print(match)\n",
    "    title, author = match\n",
    "    with open(filepath, 'rb') as f:\n",
    "        pdf = pdftotext.PDF(f)\n",
    "        for page in pdf:\n",
    "            text += page\n",
    "    return get_text_chunks_langchain(text, title, author)\n",
    "\n",
    "\n",
    "\"\"\" Unit test \"\"\"\n",
    "# pdf_files = [\"./GA_papers/CMA_ES.pdf\", \"./GA_papers/SBX.pdf\", './GA_papers/HypE.pdf']\n",
    "directory = './GA_papers/'\n",
    "pattern = '*.pdf'\n",
    "pdf_files = glob.glob(os.path.join(directory, pattern))\n",
    "\n",
    "documents = []\n",
    "bib_file = \"./bib_data/paper_metadata_full.bib\"\n",
    "\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    # print(pdf_file)\n",
    "    docs = load_pdf(pdf_file, bib_file)\n",
    "    documents += docs\n",
    "    \n",
    "print(documents[-1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da143d",
   "metadata": {},
   "source": [
    "# 2. Preparation for Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "545b518c-6ffc-4d75-b9eb-99ba6e3f6e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5763fd72-f101-4774-9993-1ea0da2ba6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load model from local files\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_path = '/data1/model/bge1_5-large-zh'\n",
    "llm_path = '/data1/model/qwen1_5-7b-chat'\n",
    "\n",
    "model = AutoModel.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763c9bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence_transformers chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6458b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488be172-bb63-4281-a6c3-27367e716dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Deb, K.', 'title': 'Scalable multi-objective optimization test problems'}\n",
      "XM) and the objective function values lie on the linear hyper-\n",
      "plane: E:=, fk = 0.5. A value of k = 5 is suggested\n",
      "here. In the above problem, the total number of variables\n",
      "is n = M + k - 1. The difficulty in this problem is to converge\n",
      "to the hyper-\n",
      "{'author': 'Deb, Kalyanmoy', 'title': 'Simulated Binary Crossover for Continuous Search Space'}\n",
      "operators need modified to solve t he above problems , similar reproduct ion\n",
      "techniques can be used along with the SBX op erator used in t his study t o\n",
      "investigat e t he efficacy of real-cod ed GA s in mult imodal and mu lt iob jective\n",
      "problems defi\n",
      "{'author': 'Deb, Kalyanmoy', 'title': 'Simulated Binary Crossover for Continuous Search Space'}\n",
      "flexible t he ope rator is in creating an arb itrary point in t he sear ch space. A\n",
      "number of crit eria for the successful design of a crossover operator ar e suggested in [7] . T hat study shows how different existing crossover op erators\n",
      "satisfy t \n",
      "{'author': 'Deb, Kalyanmoy', 'title': 'Simulated Binary Crossover for Continuous Search Space'}\n",
      "Complex Systems 9 (1995) 115-148\n",
      "Simulated Binary Crossover for\n",
      "Continuous Search Space\n",
      "Kalya nmoy D eb'\n",
      "Ram B hushan A gr awal\n",
      "Departm ent of Mechanical Engineering,\n",
      "Indi an Insti tu te of Technology,\n",
      "Ka np ur, UP 208 016, India,\n",
      "Abst ract . T he su\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lzc/.conda/envs/huawei/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "### Embed documents into vectordb\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, HuggingFaceBgeEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_path = '/data1/model/bge1_5-large-zh'\n",
    "# embeddings = SentenceTransformer(model_name_or_path=model_path, local_files_only=True)\n",
    "\n",
    "# current directory: /home/lzc/mindspore/ChatBabel.ipynb\n",
    "# embeddings = HuggingFaceBgeEmbeddings(model_name='BAAI/bge-large-zh-v1.5', cache_folder=model_path)\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(model_name=model_path)#, cache_folder=model_path)\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "vector_store.add_documents(documents)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\"\"\" Unit test \"\"\"\n",
    "query = \"A crossover operator in the continuous space.\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04fb4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Deb, K.', 'title': 'Scalable multi-objective optimization test problems'}\n",
      "XM) and the objective function values lie on the linear hyper-\n",
      "plane: E:=, fk = 0.5. A value of k = 5 is suggested\n",
      "here. In the above problem, the total number of variables\n",
      "is n = M + k - 1. The difficulty in this problem is to converge\n",
      "to the hyper-\n",
      "{'author': 'Deb, Kalyanmoy', 'title': 'Simulated Binary Crossover for Continuous Search Space'}\n",
      "operators need modified to solve t he above problems , similar reproduct ion\n",
      "techniques can be used along with the SBX op erator used in t his study t o\n",
      "investigat e t he efficacy of real-cod ed GA s in mult imodal and mu lt iob jective\n",
      "problems defi\n",
      "{'author': 'Deb, Kalyanmoy', 'title': 'Simulated Binary Crossover for Continuous Search Space'}\n",
      "flexible t he ope rator is in creating an arb itrary point in t he sear ch space. A\n",
      "number of crit eria for the successful design of a crossover operator ar e suggested in [7] . T hat study shows how different existing crossover op erators\n",
      "satisfy t \n",
      "{'author': 'Deb, Kalyanmoy', 'title': 'Simulated Binary Crossover for Continuous Search Space'}\n",
      "Complex Systems 9 (1995) 115-148\n",
      "Simulated Binary Crossover for\n",
      "Continuous Search Space\n",
      "Kalya nmoy D eb'\n",
      "Ram B hushan A gr awal\n",
      "Departm ent of Mechanical Engineering,\n",
      "Indi an Insti tu te of Technology,\n",
      "Ka np ur, UP 208 016, India,\n",
      "Abst ract . T he su\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Unit test \"\"\"\n",
    "query = \"A crossover operator in the continuous space.\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.metadata)\n",
    "    print(doc.page_content[:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a327db4-139f-4a8c-b179-92436c7f0377",
   "metadata": {},
   "source": [
    "# 3. Preparation for LLM module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62b78e1-27d1-4a8d-b1d3-cd4199499435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.738 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07cb07f99ae4975a38e86873487d6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MindSpore do not support bfloat16 dtype, we will automaticlly convert to float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM<\n",
       "  (model): Qwen2Model<\n",
       "    (embed_tokens): Embedding<vocab_size=151936, embedding_size=4096, use_one_hot=False, weight=Parameter (Tensor(shape=[151936, 4096], dtype=Float16, value=[...], name=model.embed_tokens.weight), requires_grad=True), dtype=Float32, padding_idx=None>\n",
       "    (layers): CellList<\n",
       "      (0): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (1): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (2): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (3): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (4): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (5): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (6): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (7): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (8): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (9): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (10): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (11): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (12): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (13): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (14): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (15): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (16): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (17): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (18): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (19): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (20): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (21): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (22): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (23): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (24): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (25): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (26): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (27): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (28): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (29): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (30): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      (31): Qwen2DecoderLayer<\n",
       "        (self_attn): Qwen2Attention<\n",
       "          (q_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (k_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (v_proj): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n",
       "          (o_proj): Dense<input_channels=4096, output_channels=4096>\n",
       "          (rotary_emb): Qwen2RotaryEmbedding<>\n",
       "          >\n",
       "        (mlp): Qwen2MLP<\n",
       "          (gate_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (up_proj): Dense<input_channels=4096, output_channels=11008>\n",
       "          (down_proj): Dense<input_channels=11008, output_channels=4096>\n",
       "          (act_fn): SiLU<>\n",
       "          >\n",
       "        (input_layernorm): Qwen2RMSNorm<>\n",
       "        (post_attention_layernorm): Qwen2RMSNorm<>\n",
       "        >\n",
       "      >\n",
       "    (norm): Qwen2RMSNorm<>\n",
       "    >\n",
       "  (lm_head): Dense<input_channels=4096, output_channels=151936>\n",
       "  >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "llm_path = '/data1/model/qwen1_5-7b-chat'\n",
    "model = AutoModelForCausalLM.from_pretrained(llm_path)\n",
    "model.set_train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02edcb62-6375-4a00-a3e5-8f6c85618187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(llm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331d6cc4",
   "metadata": {},
   "source": [
    "# 4. Asking ChatBabel questions about research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37af1b5e-e8a4-4d35-b295-e5da41935ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303c8f9cbdac4d9ba4c461914c1bd163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨çç ç©¶æ³æ³å¨å·²ç¥ä¿¡æ¯çæç®ä¸­ææä½ç°ãDebææç\"Simulated Binary Crossover for Continuous Search Space\"æ¢è®¨äºå¨è¿ç»­æç´¢ç©ºé´ä¸­ä½¿ç¨å®å¼ç¼ç çéä¼ ç®æ³ï¼è¿ç§æ¹æ³æ¶åå°æ¨¡æäºè¿å¶äº¤åæä½ãæ¨æå°çå°åå¼æä½çæ¦çåå¸å»ºæ¨¡å°è¿ç»­ç©ºé´å¹¶è¿è¡å®å¼äº¤åæä½ï¼ä¸è¯¥ç ç©¶ä¸­è®¨è®ºçå¤çè¿ç»­åéåè®¾è®¡è¿ç»­ç¼ç æ¹å¼çæ¦å¿µç¸å»åãç¶èï¼å·ä½çæ°å­¦æ¨¡ååææéè¦éè¿å®éªæ¥éªè¯ï¼èæ¨çåæ°ç¹å¨äºå¦ä½å°ä¼ ç»äºåäº¤åç­ç¥æ©å±å°å®å¼ç©ºé´ãå¦æè¿æ¯å¯¹ç°æå·¥ä½çä¸ä¸ªæ¹è¿ï¼å¯è½ä¼ä¸ºä¼åé®é¢æä¾æ°çè§£å³æ¹æ¡ã\n",
      "\n",
      "åèèµæï¼\n",
      "{\"author\": \"Deb, Kalyanmoy\", \"title\": \"Simulated Binary Crossover for Continuous Search Space\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mindspore import Tensor\n",
    "from mindspore import context\n",
    "from mindnlp.transformers import TextIteratorStreamer\n",
    "from threading import Thread\n",
    "import json\n",
    "\n",
    "def stream_generate_answer(\n",
    "    input_ids,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    max_new_tokens=300,\n",
    "    temperature=0.8,\n",
    "    repetition_penalty=1.0,\n",
    "    context_len=2048\n",
    "):\n",
    "    streamer = TextIteratorStreamer(tokenizer, timeout=60.0, skip_prompt=True, skip_special_tokens=True)\n",
    "    max_src_len = context_len - max_new_tokens - 8\n",
    "    input_ids = input_ids[-max_src_len:]\n",
    "    \n",
    "    input_ids = Tensor(input_ids)\n",
    "    \n",
    "    generation_kwargs = dict(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        streamer=streamer,\n",
    "    )\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "\n",
    "    yield from streamer\n",
    "\n",
    "def answer(prompt):\n",
    "\tcontext_str = \"\"\n",
    "\tretrieved_docs = retriever.get_relevant_documents(prompt)\n",
    "\tfor doc in retrieved_docs:\n",
    "\t\tcontext_str += json.dumps(doc.metadata)\n",
    "\t\tcontext_str += '\\n'\n",
    "\t\tcontext_str += doc.page_content[:250]\n",
    "\t\tcontext_str += '\\n'\n",
    "\n",
    "\tPROMPT_TEMPLATE = \"\"\"åºäºä»¥ä¸å·²ç¥ä¿¡æ¯ï¼ç®æ´åä¸ä¸çåç¥ç¨æ·ä»ä»¬çç ç©¶æ³æ³æ¯å¦åºç°å¨å·²ç¥ä¿¡æ¯çæç®ä¸­ã\n",
    "\tè¯·æä¾ç¸å³æ¡ç®çæ é¢ä»¥åä½èï¼ä¸åè®¸å¨ç­æ¡ä¸­æ·»å ç¼é æåï¼ç­æ¡è¯·ä½¿ç¨ä¸­æã\n",
    "\n",
    "\tå·²ç¥ä¿¡æ¯ï¼\n",
    "\t{context}\n",
    "\n",
    "\tè¯·ä»ç»æèå¹¶åç­ã\n",
    "\t\"\"\".format(context=context_str)\n",
    "\n",
    "\tmessages = [\n",
    "\t\t{\"role\": \"system\", \"content\": PROMPT_TEMPLATE},\n",
    "\t\t{\"role\": \"user\", \"content\": prompt}\n",
    "\t]\n",
    "\n",
    "\tinput_ids = tokenizer.apply_chat_template(\n",
    "\t\tconversation=messages,\n",
    "\t\ttokenize=True,\n",
    "\t\tadd_generation_prompt=True,\n",
    "\t\treturn_tensors='ms'\n",
    "\t)\n",
    "\n",
    "\tresponse = \"\"\n",
    "\tfor new_text in stream_generate_answer(input_ids, tokenizer, model):\n",
    "\t\tresponse += new_text\n",
    "\tresponse = response.strip()\n",
    "\n",
    "\n",
    "\tunique_metadata = []\n",
    "\tfor retrieved_doc in retrieved_docs:\n",
    "\t\tmetadata = retrieved_doc.metadata\n",
    "\t\tif metadata['author'] in ('None', 'Unknown author') or metadata['title'] in ('None', 'Unknown title'):\n",
    "\t\t\tpass\n",
    "\t\telif metadata not in unique_metadata:\n",
    "\t\t\tunique_metadata.append(metadata)\n",
    "\n",
    "\treferences = \"\\nåèèµæï¼\\n\"\n",
    "\tfor item in unique_metadata:\n",
    "\t\treferences += json.dumps(item)\n",
    "\t\treferences += '\\n'\n",
    "\n",
    "\treturn response, references\n",
    "\n",
    "# prompt = \"I have a new idea! For a LLM, it's almost impossible to pre-train from scratch: too costly. A solution is to freeze all the parameters, and create a new low-rank estimation of the original weights and train those weights with reduced parameters. What do you think?\"\n",
    "prompt = \"\"\"\n",
    "I have a new idea! for evolutionary algorithms, we usually perform the crossover operation on discrete strings. \n",
    "but we could study the probability distribution of the variation operator and mathematically model them in a continuous space to\n",
    "perform a real-valued crossover operation. what do you think of this idea?\n",
    "\"\"\"\n",
    "\n",
    "ç­æ¡æ¯æ­£ç¡®çï¼æåºäºDebææçSimulated Binary Crossoveræç®ã\n",
    "\n",
    "response, references = answer(prompt)\n",
    "print(response)\n",
    "print(references)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "617439a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6601048076b142ba8dad3894147ba6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ±æ­ï¼æ¨çç ç©¶æ³æ³ä¸å¨å·²ç¥ä¿¡æ¯çæç®ä¸­ãæç®ä¸­æå°çåå®¹ä¸æ¶åé¢è®­ç»æ¨¡åçåæ°å»ç»åä½rankä¼°è®¡ï¼èæ¯è®¨è®ºäºå¤ç®æ ä¼åç®æ³çæ§è½ä¾èµäºParetoåæ²¿å½¢ç¶ãéä¼ å±é¨æç´¢ç®æ³å¨ç¹å®é®é¢ä¸çé¾åº¦ã niched-penalty æ¹æ³å¨éä¼ ç®æ³ä¸­çåºç¨ï¼ä»¥åå¦ä½å¤ççº¦æãæ¨çæ³æ³ä¸è¿äºä¸»é¢æ å³ã\n",
      "\n",
      "åèèµæï¼\n",
      "{\"author\": \"Ishibuchi, Hisao\", \"title\": \"Performance of Decomposition-Based Many-Objective Algorithms Strongly Depends on Pareto Front Shapes\"}\n",
      "{\"author\": \"Ishibuchi, H.\", \"title\": \"A multi-objective genetic local search algorithm and its application to flowshop scheduling\"}\n",
      "{\"author\": \"Deb, Kalyanmoy\", \"title\": \"A Niched-Penalty Approach for Constraint Handling in Genetic Algorithms\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"I have a new idea! For a LLM, it's almost impossible to pre-train from scratch: too costly. \n",
    "A solution is to freeze all the parameters, and create a new low-rank estimation of the original weights and train those weights with reduced parameters. \n",
    "What do you think?\"\"\"\n",
    "\n",
    "ç­æ¡æ¯æ­£ç¡®çï¼å ä¸ºæ°æ®åºéæ²¡æè¿ä¸ªæç®ã\n",
    "\n",
    "response, references = answer(prompt)\n",
    "print(response)\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e3a098e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987de57d94994cd2991480c56d1d6aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨çç ç©¶æ³æ³å¯è½ä¸ä»¥ä¸æ¡ç®ç¸å³ï¼\n",
      "\n",
      "1. \"Compaction of symbolic layout using genetic algorithms\" by M. P. Fourman (198Swapãè¿ç¯è®ºæè®¨è®ºäºä½¿ç¨éä¼ ç®æ³è¿è¡ç¬¦å·å¸å±çåç¼©ï¼è½ç¶å®å¯è½ä¸ç´æ¥æ¶åæ°çéä¼ ç®æ³è®¾è®¡ï¼ä½éä¼ ç®æ³çæ¦å¿µååºç¨æä¾äºåºç¡ã\n",
      "\n",
      "2. å¦ææ¨æ³æ¯è¾æè¯ä¼°ä¸åçéä¼ ç®æ³ï¼ZitzleråEckartç\"Comparison of Multiobjective Evolutionary Algorithms: Empirical Results\"å¯è½ä¼æä¾æä»·å¼çä¿¡æ¯ãä»ä»¬çç ç©¶å¯è½åå«äºå¯¹æ°ç®æ³æ§è½çåæã\n",
      "\n",
      "3. å¦ææ¨çæ°ç®æ³ä¸æééæ©æç»åä¼åæå³ï¼B.ManderickåP.Spiessensçè®ºæ\"å¦ä½éæ©æé\"å¯è½å¯¹è®¾è®¡ä¸­çéæ©ç­ç¥ææå¯åï¼å°½ç®¡ä»ä»¬æ²¡æç´æ¥æå°æ°ç®æ³ï¼ä½å¯ä»¥åèä»ä»¬çæ¹æ³è®ºã\n",
      "\n",
      "4. å¦ææ¨çç ç©¶å¾å°äºæ¿åºèµå©ï¼å¦K. Debå¨å°åº¦çç ç©¶ï¼è¿å¯è½æå³çæ¨çå·¥ä½ç¬¦åæäºç ç©¶èµå©æºæå¯¹ç ç©¶æ¹åçæå¾ï¼ä½å·ä½æ¯å¦ç¸å³éè¦æ¥çä»ä»¬çèµå©é¡¹ç®ç»èã\n",
      "\n",
      "è¯·æ³¨æï¼ç±äºæä¾çä¿¡æ¯ä¸åå«å·ä½ FulfillmentDateï¼æä»¥è¿äºæ¡ç®å¯è½ä¸å®å¨å¯¹åºæ¨çææ°ç ç©¶ï¼å»ºè®®æ¨æ¥éå·ä½æç®ä»¥è·åæåç¡®çæ¯è¾ãåæ¶ï¼æ¨å¯è½éè¦åå»ºä¸ä¸ªæ°çç ç©¶ææ¡æè®ºææ¥è¯¦ç»éè¿°æ¨çæ°ç®æ³ã\n",
      "\n",
      "åèèµæï¼\n",
      "{\"author\": \"Zitzler, Eckart\", \"title\": \"Comparison of Multiobjective Evolutionary Algorithms: Empirical Results\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I would like to create a new genetic algorithm.\"\n",
    "\n",
    "å¯ä»¥çå°ï¼è¿ä¸ªpromptçé®é¢å¤ªç¬¼ç»äºãå¾é¾ä½åºå¾å¥½çåç­ï¼æä»¬æ¥ççqwenæ¯æä¹åç­çã\n",
    "\n",
    "qwenè¯çå»ä¼åç¨æ·çç ç©¶æ³æ³ï¼å ä¸ºæ°æ®åºéæ¥æå¾å¤å¯è½è·è¿ä¸ªç¸å³çæç®ï¼ä½åå¾é¾éåºä¸æ¡å·ä½çæç®ãçè³å¯ä»¥çå°qwenæhallucinationçå¾åã\n",
    "\n",
    "response, references = answer(prompt)\n",
    "print(response)\n",
    "print(references)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huawei",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
